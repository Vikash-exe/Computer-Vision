# Computer-Vision

A comparision of Transformer and CNN models over RGB satellite imagery
This workflow is detailed study of how different architecture behave on high resolution dataset.

`````````````````````````````````````````````````````````````````````````````````````
ğŸ›° Dataset Details

Total samples: 500 imageâ€“mask pairs

Image resolution: 512 Ã— 512

Number of classes: 5 (as available in the dataset)

Task: Pixel-wise semantic segmentation

Data split: Train / Validation 

Each mask contains integer-encoded class labels corresponding to five semantic land-cover categories.
``````````````````````````````````````````````````````````````````````````````````````
ğŸ§  Models Compared
1ï¸âƒ£ ResNet50-based Segmentation

Backbone: ResNet50

Encoder-decoder architecture

Pretrained weights used for initialization

Fine-tuned on satellite dataset

2ï¸âƒ£ ResNet101-based Segmentation

Deeper backbone than ResNet50

Higher representational capacity

Increased parameter count

3ï¸âƒ£ SegFormer B0

Transformer-based segmentation architecture

Efficient attention mechanism

Strong performance on dense prediction tasks 
````````````````````````````````````````````````````````````````````````````````````````````
âš™ï¸ Training Configuration
ğŸ”¹ Input Size

512 Ã— 512

ğŸ”¹ Loss Function

Cross-Entropy Loss



ğŸ”¹ Optimizer

Adam / AdamW

ğŸ”¹ Learning Rate Strategy

Tuned across multiple values

Scheduler applied (if used)

ğŸ”¹ Batch Size

4

ğŸ”¹ Epochs:10

(Insert value)

ğŸ”¬ Hyperparameter Tuning

Hyperparameters tuned:

Learning rate: 1e-7

Batch size : 4

Optimizer selection :  adam

Best configurations were selected based on validation performance.
```````````````````````````````````````````````````````````````````````````````````````````
ğŸ“Š Evaluation Metrics

Models were evaluated using:

Pixel Accuracy

Mean Intersection over Union (mIoU)

Confusion Matrix

